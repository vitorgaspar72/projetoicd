{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pratica_integrada_s1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitorgaspar72/projetoicd/blob/main/pratica_integrada_s1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando bibliotecas"
      ],
      "metadata": {
        "id": "ytYn-sG4OBZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "# !pip install pandasql\n",
        "import pandasql as sql\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "kNPAmFXrN7nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Faz a busca de dados na página HTML e refina os dados"
      ],
      "metadata": {
        "id": "EJZxIyADNVZN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLjrLHKPlxmT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def pegar_dados_eventos():\n",
        "  r = requests.get('https://nuforc.org/webreports/ndxevent.html')\n",
        "  html = r.text\n",
        "  array_html = html.split(\"<TBODY>\")\n",
        "  linhas_com_sujeira = array_html[1].split(\"</TBODY>\")\n",
        "  linhas = linhas_com_sujeira[0]\n",
        "\n",
        "  celulas = linhas.split(\"<TD>\")\n",
        "  celulas\n",
        "  a_href_com_sujeira = map(lambda i: i.split('<FONT style=FONT-SIZE:11pt FACE=\"Calibri\" COLOR=#000000>'), celulas)\n",
        "  a_href_com_sujeira = list(a_href_com_sujeira)\n",
        "\n",
        "  del(a_href_com_sujeira[0])\n",
        "  a_href_com_sujeira.pop()\n",
        "\n",
        "  valor_celulas = map(lambda x: x[0].split(\"</TD>\"), a_href_com_sujeira)\n",
        "  valor_celulas = list(valor_celulas)\n",
        "\n",
        "  valor_celulas = map(lambda x: x[0], valor_celulas)\n",
        "  valor_celulas = list(valor_celulas)\n",
        "\n",
        "  linhas_uteis = filter(lambda x: \"<A \" in x , valor_celulas)\n",
        "  linhas_uteis = list(linhas_uteis)\n",
        "\n",
        "  link_data_com_sujeira = map(lambda x: x.split(\"<\"), valor_celulas)\n",
        "  link_data_com_sujeira = list(link_data_com_sujeira)\n",
        "\n",
        "  return link_data_com_sujeira\n",
        "  link_data_com_sujeira = filter(lambda x: x[1] is not None, link_data_com_sujeira)\n",
        "  link_data_com_sujeira = list(link_data_com_sujeira)\n",
        "\n",
        "  # a_href = list()\n",
        "  # return a_href_com_sujeira[1]\n",
        "  # for a in a_href_com_sujeira:\n",
        "  #   a_href.append(a[1])\n",
        "\n",
        "  links_com_sujeira = map(lambda x: x.split(\"<A HREF= \"), a_href)\n",
        "\n",
        "  links = list()\n",
        "  datas = list()\n",
        "  link_data = list()\n",
        "  for l in links_com_sujeira:\n",
        "    link = l[1].split('>')[0]\n",
        "    data_mes_ano = l[1].split('>')[1].split('</A')[0]\n",
        "\n",
        "    data = data_mes_ano.split(\"/\")\n",
        "    data = datetime.date(int(data[1]), int(data[0]), 1)\n",
        "    # date = datetime.date(2020, 12, 16)\n",
        "\n",
        "    # data = datetime.strptime(data_com_dia, \"%d/%m/%Y\").date()\n",
        "    link_data.append(dict({\n",
        "      \"link\":link,\n",
        "      \"data\": data\n",
        "    }))\n",
        "\n",
        "  return link_data\n",
        "\n",
        "link_date = pegar_dados_eventos()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determina o intervalo de anos cadastrados que será feita a busca de dados"
      ],
      "metadata": {
        "id": "mmOEX7iRNLiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_valid_events():\n",
        "  events = list()\n",
        "  for a in range(1997, 2018):\n",
        "    for m in range(1, 13):\n",
        "      mes = str(m).zfill(2)\n",
        "      events.append(dict({\n",
        "        \"link\": f\"ndxe{a}{mes}.html\",\n",
        "        \"data\": datetime.date(int(a), int(m), 1)\n",
        "      }))\n",
        "\n",
        "  return events\n",
        "\n",
        "link_date = get_valid_events()"
      ],
      "metadata": {
        "id": "LWWHI3mc3PLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Determina o intervalo de busca na página HTML que será feita a busca de dados"
      ],
      "metadata": {
        "id": "Vx1jQrnzM10s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_inicio = first_date = datetime.date(1997, 9, 1)\n",
        "data_fim = first_date = datetime.date(2017, 8, 1)\n",
        "\n",
        "paginas_intervalo = filter(lambda x: x['data'] >= data_inicio and x['data'] <= data_fim, link_date)\n",
        "paginas_intervalo = list(paginas_intervalo)\n"
      ],
      "metadata": {
        "id": "I1562MlK1tp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Obtém os dados do intervalo definido de busca e faz o refinamento dos dados"
      ],
      "metadata": {
        "id": "0K6LQAwoMuAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunks(lst, n):\n",
        "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]\n",
        "\n",
        "def buscar_dados_tabulados(link_data):\n",
        "  df = {\n",
        "    'date_time',\n",
        "    'city',\n",
        "    'state',\n",
        "    'country',\n",
        "    'shape',\n",
        "    'duration',\n",
        "    'summary',\n",
        "    'posted',\n",
        "    'images'\n",
        "  }\n",
        "\n",
        "  df = pd.DataFrame(columns=df)\n",
        "  lista_dados_padronizados = []\n",
        "\n",
        "  for l in link_data:\n",
        "    r = requests.get(f\"https://nuforc.org/webreports/{l['link']}\")\n",
        "\n",
        "    soup = BeautifulSoup(r.text, 'html.parser')\n",
        "    table = soup.find('table')\n",
        "\n",
        "    linhas = table.findAll(\"tr\")\n",
        "\n",
        "    data = []\n",
        "    for row in linhas:\n",
        "      cells = row.findAll(\"td\")\n",
        "      cols = [ele.text.strip() for ele in cells]\n",
        "\n",
        "      if cols != []:\n",
        "        data.append(list(chunks(cols, 9)))\n",
        "        break\n",
        "\n",
        "    for d in data[0]:\n",
        "      dados_padronizados = {\n",
        "        'date_time': d[0],\n",
        "        'city':d[1],\n",
        "        'state':d[2],\n",
        "        'country':d[3],\n",
        "        'shape':d[4],\n",
        "        'duration':d[5],\n",
        "        'summary':d[6],\n",
        "        'posted':d[7],\n",
        "        'images':d[8] if d[8] != \"\" else \"No\"\n",
        "      }\n",
        "      lista_dados_padronizados.append(dados_padronizados)\n",
        "\n",
        "  df = df.append(lista_dados_padronizados, ignore_index = True)\n",
        "\n",
        "  return df \n",
        "  \n",
        "aparicoes_df = buscar_dados_tabulados(paginas_intervalo)\n",
        "\n"
      ],
      "metadata": {
        "id": "2d25x3yE2oiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converte todos os dados obtidos e filtrados do site em CSV"
      ],
      "metadata": {
        "id": "ELm8RfCZMk_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aparicoes_df.to_csv(\"aparicoes.csv\")"
      ],
      "metadata": {
        "id": "8nH-BS57Cepf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantidade de aparições informadas"
      ],
      "metadata": {
        "id": "nLGZx4Qh8ffB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "linhasGeradas= aparicoes_df.shape[0]\n",
        "linhasGeradas "
      ],
      "metadata": {
        "id": "aqk2-yu97_4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aparições por Estado(EUA) em ordem decrescente"
      ],
      "metadata": {
        "id": "YYDbq7hu9EvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aparicoesPorEstado= \"SELECT state as Estado ,count(state) as Aparicoes from aparicoes_df WHERE state != '' AND country='USA' GROUP BY state ORDER BY aparicoes DESC\"\n",
        "aparicoesPorEstado=sql.sqldf(aparicoesPorEstado,locals())\n",
        "print(aparicoesPorEstado.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "SW5N9d4t9JzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consulta por Cidades dos EUA(Mínimo de Aparições=10)"
      ],
      "metadata": {
        "id": "8yFP3ZC_HH2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aparicoesPorCidade= \"SELECT city as Cidade ,count(city) as Aparicoes from aparicoes_df WHERE state != '' AND country='USA' GROUP BY city ORDER BY aparicoes DESC\"\n",
        "aparicoesPorCidade=sql.sqldf(aparicoesPorCidade,locals())\n",
        "aparicoesMaioresQueDez= aparicoesPorCidade.query('Aparicoes>=10')\n",
        "print(aparicoesMaioresQueDez.to_string(index=False))"
      ],
      "metadata": {
        "id": "RyZ6rQkYHNqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Porque Phoenix é a cidade que mais informa aparições?\n",
        "R= Está perto da Área 51"
      ],
      "metadata": {
        "id": "4YRAJcgmJgoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Consulta de Aparições no Estado Americano com mais registros(Califórnia, mínimo 10 aparições por cidade)"
      ],
      "metadata": {
        "id": "Oo0Q3h0ZKYLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aparicoesCalifornia= \"SELECT city as Cidade ,count(city) as Aparicoes,shape as FormatoObjeto from aparicoes_df WHERE state = 'CA' AND country='USA'  GROUP BY city ORDER BY aparicoes DESC\"\n",
        "aparicoesCalifornia=sql.sqldf(aparicoesCalifornia,locals())\n",
        "aparicoesMaioresQueDez= aparicoesCalifornia.query(\"Aparicoes>=10 & FormatoObjeto !='' \")\n",
        "print(aparicoesMaioresQueDez.to_string(index=False))"
      ],
      "metadata": {
        "id": "JRDFX3UfKOEV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}